---
layout: default
title: "Home"
---

<br><br>
<div style="text-align: center; font-size: 2em; font-weight: bold;">
  UDC-VIT: A Real-World Video Dataset for Under-Display Cameras
  리뷰어한테 배포하지 말라고 쓰기
</div>

<div style="text-align: center; font-size: 1.5em; font-weight: normal; color: #666;">
  This is a description that appears in a slightly less bold color.
<!--   <img src="videos/jiwon_wipe-ezgif.com-video-to-gif-converter.gif" style="max-width: 1200px;"> -->
  <video width="800" controls loop="" muted = "" autoplay="">
    <source src ="https://github.com/jisoo1738/contrasttest.github.io/raw/master/videos/jiwon_wipe.mov">
  </video>
</div>
<div style="text-align: center; font-size: 1.2em; font-weight: 300; color: #888;">
  The UDC-VIT dataset captures the movements of various subjects such as people and objects in<br>
  both indoor and outdoor environments, capturing real-UDC degradations.
</div>

<br><br>
<div style="text-align: center; font-size: 2em; font-weight: bold;">
  RESULTS
</div>

####
<div style="text-align: center; font-size: 2em; font-weight: bold;">
  About
</div>

<div style="text-align: left; font-size: 1.2em; font-weight: normal; color: #666; margin: 20px;">
  <h1>Who created this dataset?</h1>
  <p>The UDC-VIT dataset is created by Thunder Research Group at Seoul National University. 
    <a href="https://thunder.snu.ac.kr/~kyusu/">Kyusu Ahn</a>, Sangik Lee, <a href="https://github.com/jisoo1738">JiSoo Kim</a>,
    <a href="https://hyungyulee7.github.io">HyunGyu Lee</a>, <a href="https://sites.google.com/view/devko">Byeonghyun Ko</a> are the authors of the paper,
    with <a href="https://sites.google.com/view/jaejinlee">Jaejin Lee</a> as the corresponding author.
  </p>

  <h1>How can I download the dataset?</h1>
  <p>We have provided a direct download link for the datasets below for the reviewers' convenience.
    We provide the download link for VidUDC33K to help reviewers compare UDC-VIT with a previous synthetic dataset. 
    The original authors preserve all rights for VidUDC33K. 
    Refer to the <a href="https://github.com/ChengxuLiu/DDRNet">original repositories</a> for more details.
  </p>

  <p>With the camera ready, the UDC-VIT users can download the datasets through Thunder Research Group's homepage, which is not currently available.</p>

  <ul>
    <li><a href="https://drive.google.com/file/d/1nDfUkU8cy2KPSZwQLe3wcI9ttLhrATlk/view?usp=drive_link">UDC-VIT in mp4 format (only accessible to the reviewers)</a></li>
    <li>UDC-VIT - training set</li>
    <li>UDC-VIT - validation set</li>
    <li>UDC-VIT - test set</li>
    <li><a href="https://drive.google.com/file/d/1Db4sYo4dnNIxdH20J7fseE9vjzRMk0OL/view?usp=drive_link">UDC-VIT - metadata</a></li>
    <li>VidUDC33K in mp4 format (only accessible to the reviewers)</li>
  </ul>
</div>


####
{% if site.show_excerpts %}
  {% include home.html %}
{% else %}
  {% include archive.html title="Posts" %}
{% endif %}
